{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a3447ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete debug data collection from class model to run for extended periods of time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class KeypointClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KeypointClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(21*3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 21*3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "import pyautogui\n",
    "\n",
    "pyautogui.PAUSE = 0.01\n",
    "\n",
    "def zoom(amount):\n",
    "    pyautogui.keyDown('ctrl')\n",
    "    pyautogui.scroll(-int(amount*2000))\n",
    "    pyautogui.keyUp('ctrl')\n",
    "\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "with open('model1401.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "class model():\n",
    "    def __init__(self):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands()\n",
    "    \n",
    "    def findHands(self, image):\n",
    "        self.results = self.hands.process(image)\n",
    "        \n",
    "    def drawHands(self, image):\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for hand_landmarks in self.results.multi_hand_landmarks:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(image, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "        return image\n",
    "    \n",
    "    def getKeypoints(self):\n",
    "        data = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for hand_landmarks in self.results.multi_hand_landmarks:\n",
    "                for i, landmark in enumerate(hand_landmarks.landmark):\n",
    "                    data.append([landmark.x, landmark.y, landmark.z])\n",
    "        data = np.array(data)\n",
    "        \n",
    "        hands = []\n",
    "        centers = []\n",
    "        for i in range(0, data.shape[0], 21):\n",
    "            hands.append(data[i:i+21])\n",
    "            centers.append(np.mean(hands[-1], axis = 0).reshape(3))\n",
    "        hands = np.array(hands).reshape(-1, 21, 3)\n",
    "        centers = np.array(centers).reshape(-1, 3)\n",
    "            \n",
    "        if len(centers.shape) == 2 and centers.shape[0] >= 2:\n",
    "            dist = (np.sum((centers[0, :2] - centers[1, :2])**2))**0.5\n",
    "        else:\n",
    "            dist = None\n",
    "        \n",
    "        dataset = {\n",
    "            \"hands\": hands,\n",
    "            \"centers\": centers,\n",
    "            \"distance\": dist\n",
    "        }\n",
    "        return dataset\n",
    "   \n",
    "\n",
    "     \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920//4)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080//4)\n",
    "dataset = []\n",
    "\n",
    "h = model()\n",
    "prev = time.time()\n",
    "history = []\n",
    "\n",
    "while True:\n",
    "    # Read frame, make it rgb and flip\n",
    "    ret, frame = cap.read()\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    # Find keypoints, draw them and get back useful data\n",
    "    h.findHands(image)\n",
    "    image = h.drawHands(image)\n",
    "    data = h.getKeypoints()\n",
    "    \n",
    "    # Reshape bgr image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    image = cv2.resize(image, (1280, 720))\n",
    "    \n",
    "    # find centers\n",
    "    if len(data[\"centers\"]) > 0:\n",
    "        for x, y, z in data[\"centers\"]:\n",
    "            image = cv2.circle(image, (int(x*1280), int(y*720)), 10, (255, 255, 255), -1)\n",
    "    \n",
    "    tuttiPugni = True\n",
    "    n = 0\n",
    "    for n, hand in enumerate(data[\"hands\"]):\n",
    "        pugno = loaded_model(torch.tensor(hand).view(1, 63).to(device).float())[0][0] > 0.5\n",
    "        if pugno:\n",
    "            cv2.putText(image, \"Pugno\", (20, 50+50*n), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            tuttiPugni = False\n",
    "            cv2.putText(image, \"Mano aperta\", (20, 50+50*n), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    if tuttiPugni and data[\"distance\"] != None:\n",
    "        history.append(data[\"distance\"]) \n",
    "        cv2.putText(image, str(data[\"distance\"]), (20, 50+50*(n+1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        if len(history) > 3:\n",
    "            zoom(history[-3]-history[-1]) # zoom(hist)\n",
    "    else:\n",
    "        history = []\n",
    "        cv2.putText(image, str(data[\"distance\"]), (20, 50+50*(n+1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "    cv2.putText(image, str(round(1/(time.time()-prev), 1)), (20, 50+50*(n+2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    prev = time.time()\n",
    "    \n",
    "    cv2.imshow('Hand Tracking', cv2.resize(image, (1600//2, 900//2)))\n",
    "\n",
    "    # Step 10: Break the loop if the user presses the 'q' key\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# Step 9: Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
